
```python
import time
import random
from abc import ABC, abstractmethod
from queue import Queue
from threading import Thread, Lock


# Abstract Task class (Interface)
class Task(ABC):
    @abstractmethod
    def execute(self):
        pass


# CPU Bound Task
class CPUBoundTask(Task):
    def __init__(self, task_name):
        self.task_name = task_name

    def execute(self):
        print(f"Executing CPU Bound Task: {self.task_name}")
        # Simulating CPU-bound operation (e.g., a complex calculation)
        result = sum(i * i for i in range(10000000))  # Just a CPU-intensive task
        print(f"Task {self.task_name} completed (CPU-bound)")


# IO Bound Task
class IOBoundTask(Task):
    def __init__(self, task_name):
        self.task_name = task_name

    def execute(self):
        print(f"Executing IO Bound Task: {self.task_name}")
        # Simulating I/O-bound operation (e.g., network or file I/O)
        time.sleep(random.randint(1, 3))  # Simulating network delay
        print(f"Task {self.task_name} completed (IO-bound)")


# Task Factory to create tasks dynamically
class TaskFactory:
    @staticmethod
    def create_task(task_type, task_name):
        if task_type == "cpu":
            return CPUBoundTask(task_name)
        elif task_type == "io":
            return IOBoundTask(task_name)
        else:
            raise ValueError(f"Unknown task type: {task_type}")


# Worker Class with Complex Logic (Factory Method Pattern)
class Worker(Thread):
    def __init__(self, task_queue, worker_id):
        super().__init__()
        self.task_queue = task_queue
        self.worker_id = worker_id
        self.lock = Lock()

    def run(self):
        while True:
            task = self.task_queue.get()
            if task is None:  # End condition (used for graceful shutdown)
                break

            print(f"Worker-{self.worker_id} started executing task: {task.task_name}")

            # Complex worker logic based on task type
            if isinstance(task, CPUBoundTask):
                # CPU-bound tasks may have specific resource allocation or scheduling.
                self.lock.acquire()
                task.execute()
                self.lock.release()
            elif isinstance(task, IOBoundTask):
                # I/O-bound tasks may be executed with a delay or using async strategies.
                task.execute()
            else:
                print(f"Unknown task type: {task.task_name}")

            self.task_queue.task_done()


# Singleton ThreadPool Class
class ThreadPool:
    _instance = None

    def __new__(cls, num_threads=2):
        if cls._instance is None:
            cls._instance = super(ThreadPool, cls).__new__(cls)
            cls._instance._initialize(num_threads)
        return cls._instance

    def _initialize(self, num_threads):
        self.task_queue = Queue()
        self.workers = []
        self.num_threads = num_threads
        self.shutdown_flag = False

        # Create Worker Threads
        for i in range(self.num_threads):
            worker = Worker(self.task_queue, worker_id=i+1)
            self.workers.append(worker)
            worker.start()

    def submit_task(self, task):
        if not self.shutdown_flag:
            self.task_queue.put(task)

    def shutdown(self):
        self.shutdown_flag = True
        # Shutdown workers
        for _ in self.workers:
            self.task_queue.put(None)
        for worker in self.workers:
            worker.join()


# Main Execution Example
if __name__ == "__main__":
    thread_pool = ThreadPool(num_threads=4)  # Singleton instance

    # Submitting tasks (CPU-bound and IO-bound)
    for i in range(5):
        task_cpu = TaskFactory.create_task("cpu", f"CPU_Task-{i}")
        thread_pool.submit_task(task_cpu)

    for i in range(5, 10):
        task_io = TaskFactory.create_task("io", f"IO_Task-{i}")
        thread_pool.submit_task(task_io)

    # Shutdown the thread pool after tasks are done
    thread_pool.shutdown()
```

```go
package main

import (
	"fmt"
	"math"
	"math/rand"
	"sync"
	"time"
)

// Task Interface
type Task interface {
	Execute()
}

// CPU Bound Task
type CPUBoundTask struct {
	taskName string
}

func (task *CPUBoundTask) Execute() {
	fmt.Printf("Executing CPU Bound Task: %s\n", task.taskName)
	// Simulating CPU-bound operation
	var result int
	for i := 0; i < 10000000; i++ {
		result += int(math.Sqrt(float64(i)))
	}
	fmt.Printf("Task %s completed (CPU-bound)\n", task.taskName)
}

// IO Bound Task
type IOBoundTask struct {
	taskName string
}

func (task *IOBoundTask) Execute() {
	fmt.Printf("Executing IO Bound Task: %s\n", task.taskName)
	// Simulating I/O-bound operation
	time.Sleep(time.Duration(rand.Intn(3)+1) * time.Second)
	fmt.Printf("Task %s completed (IO-bound)\n", task.taskName)
}

// Task Factory to create tasks
type TaskFactory struct{}

func (f *TaskFactory) CreateTask(taskType, taskName string) Task {
	if taskType == "cpu" {
		return &CPUBoundTask{taskName: taskName}
	} else if taskType == "io" {
		return &IOBoundTask{taskName: taskName}
	} else {
		panic("Unknown task type")
	}
}

// Worker struct
type Worker struct {
	id        int
	taskQueue chan Task
	wg        *sync.WaitGroup
}

func (w *Worker) Start() {
	for task := range w.taskQueue {
		fmt.Printf("Worker-%d started executing task: %s\n", w.id, task.(*CPUBoundTask).taskName)
		task.Execute()
		w.wg.Done()
	}
}

// ThreadPool struct (Singleton)
type ThreadPool struct {
	taskQueue chan Task
	workers   []*Worker
	wg        *sync.WaitGroup
}

var instance *ThreadPool
var once sync.Once

// NewThreadPool returns the Singleton instance of the thread pool
func NewThreadPool(numThreads int) *ThreadPool {
	once.Do(func() {
		instance = &ThreadPool{
			taskQueue: make(chan Task, 100),
			wg:        &sync.WaitGroup{},
		}

		for i := 0; i < numThreads; i++ {
			worker := &Worker{
				id:        i + 1,
				taskQueue: instance.taskQueue,
				wg:        instance.wg,
			}
			go worker.Start()
			instance.workers = append(instance.workers, worker)
		}
	})

	return instance
}

func (tp *ThreadPool) SubmitTask(task Task) {
	tp.wg.Add(1)
	tp.taskQueue <- task
}

func (tp *ThreadPool) Shutdown() {
	close(tp.taskQueue)
	tp.wg.Wait()
}

func main() {
	taskFactory := &TaskFactory{}
	threadPool := NewThreadPool(4) // Singleton instance

	// Submit tasks
	for i := 0; i < 5; i++ {
		task := taskFactory.CreateTask("cpu", fmt.Sprintf("CPU_Task-%d", i))
		threadPool.SubmitTask(task)
	}

	for i := 5; i < 10; i++ {
		task := taskFactory.CreateTask("io", fmt.Sprintf("IO_Task-%d", i))
		threadPool.SubmitTask(task)
	}

	// Shutdown the thread pool
	threadPool.Shutdown()
}
```

## Design Patterns Involved:

### Singleton Pattern:
Used to ensure only one instance of the thread pool is created, providing global access.

### Factory Method Pattern:
Used to create task objects and threads, encapsulating the instantiation logic.

### Producer-Consumer Pattern:
Implemented using a blocking queue where tasks are produced by the main thread and consumed by worker threads.

### Thread Pool Pattern:
Core pattern where a pool of threads is maintained to perform tasks concurrently.

## Another implementation which scales automatically 

```golang
package main

import (
	"context"
	"fmt"
	"math/rand"
	"sync"
	"sync/atomic"
	"time"
)

const (
	MaxWorkers   = 1000 // Upper limit on workers
	MinWorkers   = 10   // Minimum number of workers
	ScaleUpRate  = 10   // How many workers to add per scale-up
	ScaleDownRate = 5   // How many workers to remove per scale-down
	QueueSize    = 1000 // Size of the task queue
	ShutdownWait = 5 * time.Second
)

type Task struct {
	ID int
}

type WorkerPool struct {
	taskQueue     chan Task
	workerCount   int32
	mu            sync.Mutex
	wg            sync.WaitGroup
	shutdown      chan struct{}
	scaleTicker   *time.Ticker
}

func NewWorkerPool() *WorkerPool {
	pool := &WorkerPool{
		taskQueue:   make(chan Task, QueueSize),
		workerCount: MinWorkers,
		shutdown:    make(chan struct{}),
		scaleTicker: time.NewTicker(1 * time.Second),
	}

	// Start initial workers
	for i := 0; i < MinWorkers; i++ {
		pool.addWorker()
	}

	// Monitor and dynamically adjust worker count
	go pool.autoScale()

	return pool
}

// Worker logic
func (wp *WorkerPool) worker(id int) {
	wp.wg.Add(1)
	defer wp.wg.Done()

	for {
		select {
		case task := <-wp.taskQueue:
			fmt.Printf("Worker %d processing task %d\n", id, task.ID)
			time.Sleep(time.Duration(rand.Intn(50)) * time.Millisecond) // Simulate work
		case <-wp.shutdown:
			fmt.Printf("Worker %d shutting down...\n", id)
			return
		}
	}
}

// Adds a worker
func (wp *WorkerPool) addWorker() {
	wp.mu.Lock()
	defer wp.mu.Unlock()

	if atomic.LoadInt32(&wp.workerCount) >= MaxWorkers {
		return
	}

	workerID := int(atomic.AddInt32(&wp.workerCount, 1))
	go wp.worker(workerID)
}

// Removes a worker
func (wp *WorkerPool) removeWorker() {
	wp.mu.Lock()
	defer wp.mu.Unlock()

	if atomic.LoadInt32(&wp.workerCount) > MinWorkers {
		atomic.AddInt32(&wp.workerCount, -1)
	}
}

// Auto-scaling logic
func (wp *WorkerPool) autoScale() {
	for {
		select {
		case <-wp.scaleTicker.C:
			queueLength := len(wp.taskQueue)

			if queueLength > QueueSize/2 { // High load, scale up
				for i := 0; i < ScaleUpRate; i++ {
					wp.addWorker()
				}
			} else if queueLength < QueueSize/10 && atomic.LoadInt32(&wp.workerCount) > MinWorkers { // Low load, scale down
				for i := 0; i < ScaleDownRate; i++ {
					wp.removeWorker()
				}
			}
		case <-wp.shutdown:
			return
		}
	}
}

// Submits tasks to the queue
func (wp *WorkerPool) Submit(task Task) {
	wp.taskQueue <- task
}

// Graceful shutdown
func (wp *WorkerPool) Shutdown() {
	close(wp.shutdown)
	close(wp.taskQueue)
	wp.scaleTicker.Stop()
	wp.wg.Wait() // Wait for all workers to finish
	fmt.Println("Worker pool shut down.")
}

func main() {
	wp := NewWorkerPool()

	// Simulate task submission
	go func() {
		for i := 0; i < 100000; i++ {
			wp.Submit(Task{ID: i})
			time.Sleep(10 * time.Microsecond) // Simulate constant task stream
		}
	}()

	// Run for 10 seconds, then shutdown
	time.Sleep(10 * time.Second)
	wp.Shutdown()
}
```
